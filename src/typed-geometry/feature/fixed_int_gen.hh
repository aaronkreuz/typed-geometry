#pragma once

// This file was generated by generate_fixed_uint_multiplications.cc in TGSamples.

#include <immintrin.h>

#ifndef _MSC_VER
#include <x86intrin.h>
#endif

#include <typed-geometry/feature/fixed_int.hh>

namespace tg::detail
{
template <int w_res, class T0, class T1>
fixed_int<w_res> imul(T0 const& lhs, T1 const& rhs);

template <>
fixed_int<2> imul(i64 const& lhs, i64 const& rhs)
{
    fixed_int<2> res;
    i64 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l), u64(r), &h00);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template <>
fixed_int<2> imul(i128 const& lhs, i64 const& rhs)
{
    fixed_int<2> res;
    i128 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63);      // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r), &h00);
    l10 = u64(l.d[1]) * u64(r);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template <>
fixed_int<2> imul(i192 const& lhs, i64 const& rhs)
{
    fixed_int<2> res;
    i192 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63);      // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r), &h00);
    l10 = u64(l.d[1]) * u64(r);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template <>
fixed_int<2> imul(i256 const& lhs, i64 const& rhs)
{
    fixed_int<2> res;
    i256 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63);      // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) - s_l;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r), &h00);
    l10 = u64(l.d[1]) * u64(r);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template <>
fixed_int<2> imul(i64 const& lhs, i128 const& rhs)
{
    fixed_int<2> res;
    i64 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l) >> 63);      // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l), u64(r.d[0]), &h00);
    l01 = u64(l) * u64(r.d[1]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template <>
fixed_int<2> imul(i128 const& lhs, i128 const& rhs)
{
    fixed_int<2> res;
    i128 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = u64(l.d[0]) * u64(r.d[1]);
    l10 = u64(l.d[1]) * u64(r.d[0]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template <>
fixed_int<2> imul(i192 const& lhs, i128 const& rhs)
{
    fixed_int<2> res;
    i192 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = u64(l.d[0]) * u64(r.d[1]);
    l10 = u64(l.d[1]) * u64(r.d[0]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template <>
fixed_int<2> imul(i256 const& lhs, i128 const& rhs)
{
    fixed_int<2> res;
    i256 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) - s_l;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = u64(l.d[0]) * u64(r.d[1]);
    l10 = u64(l.d[1]) * u64(r.d[0]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template <>
fixed_int<2> imul(i64 const& lhs, i192 const& rhs)
{
    fixed_int<2> res;
    i64 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l) >> 63);      // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l), u64(r.d[0]), &h00);
    l01 = u64(l) * u64(r.d[1]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template <>
fixed_int<2> imul(i128 const& lhs, i192 const& rhs)
{
    fixed_int<2> res;
    i128 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = u64(l.d[0]) * u64(r.d[1]);
    l10 = u64(l.d[1]) * u64(r.d[0]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template <>
fixed_int<2> imul(i192 const& lhs, i192 const& rhs)
{
    fixed_int<2> res;
    i192 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = u64(l.d[0]) * u64(r.d[1]);
    l10 = u64(l.d[1]) * u64(r.d[0]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template <>
fixed_int<2> imul(i256 const& lhs, i192 const& rhs)
{
    fixed_int<2> res;
    i256 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) - s_l;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = u64(l.d[0]) * u64(r.d[1]);
    l10 = u64(l.d[1]) * u64(r.d[0]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template <>
fixed_int<2> imul(i64 const& lhs, i256 const& rhs)
{
    fixed_int<2> res;
    i64 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l) >> 63);      // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) - s_r;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l), u64(r.d[0]), &h00);
    l01 = u64(l) * u64(r.d[1]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template <>
fixed_int<2> imul(i128 const& lhs, i256 const& rhs)
{
    fixed_int<2> res;
    i128 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) - s_r;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = u64(l.d[0]) * u64(r.d[1]);
    l10 = u64(l.d[1]) * u64(r.d[0]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template <>
fixed_int<2> imul(i192 const& lhs, i256 const& rhs)
{
    fixed_int<2> res;
    i192 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) - s_r;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = u64(l.d[0]) * u64(r.d[1]);
    l10 = u64(l.d[1]) * u64(r.d[0]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template <>
fixed_int<2> imul(i256 const& lhs, i256 const& rhs)
{
    fixed_int<2> res;
    i256 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) - s_l;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) - s_r;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = u64(l.d[0]) * u64(r.d[1]);
    l10 = u64(l.d[1]) * u64(r.d[0]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template <>
fixed_int<3> imul(i64 const& lhs, i64 const& rhs)
{
    fixed_int<3> res;
    i64 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l), u64(r), &h00);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template <>
fixed_int<3> imul(i128 const& lhs, i64 const& rhs)
{
    fixed_int<3> res;
    i128 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63);      // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r), &h00);
    l10 = _mulx_u64(u64(l.d[1]), u64(r), &h10);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template <>
fixed_int<3> imul(i192 const& lhs, i64 const& rhs)
{
    fixed_int<3> res;
    i192 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63);      // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 l10 = 0;
    u64 l20 = 0;
    u64 h00 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r), &h00);
    l10 = _mulx_u64(u64(l.d[1]), u64(r), &h10);
    l20 = u64(l.d[2]) * u64(r);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l20, &res.d[2]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template <>
fixed_int<3> imul(i256 const& lhs, i64 const& rhs)
{
    fixed_int<3> res;
    i256 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63);      // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) - s_l;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 l10 = 0;
    u64 l20 = 0;
    u64 h00 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r), &h00);
    l10 = _mulx_u64(u64(l.d[1]), u64(r), &h10);
    l20 = u64(l.d[2]) * u64(r);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l20, &res.d[2]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template <>
fixed_int<3> imul(i64 const& lhs, i128 const& rhs)
{
    fixed_int<3> res;
    i64 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l) >> 63);      // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    l00 = _mulx_u64(u64(l), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l), u64(r.d[1]), &h01);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template <>
fixed_int<3> imul(i128 const& lhs, i128 const& rhs)
{
    fixed_int<3> res;
    i128 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = u64(l.d[1]) * u64(r.d[1]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l11, &res.d[2]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template <>
fixed_int<3> imul(i192 const& lhs, i128 const& rhs)
{
    fixed_int<3> res;
    i192 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l20 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = u64(l.d[1]) * u64(r.d[1]);
    l20 = u64(l.d[2]) * u64(r.d[0]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l11, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l20, &res.d[2]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template <>
fixed_int<3> imul(i256 const& lhs, i128 const& rhs)
{
    fixed_int<3> res;
    i256 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) - s_l;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l20 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = u64(l.d[1]) * u64(r.d[1]);
    l20 = u64(l.d[2]) * u64(r.d[0]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l11, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l20, &res.d[2]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template <>
fixed_int<3> imul(i64 const& lhs, i192 const& rhs)
{
    fixed_int<3> res;
    i64 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l) >> 63);      // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    l00 = _mulx_u64(u64(l), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l), u64(r.d[1]), &h01);
    l02 = u64(l) * u64(r.d[2]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l02, &res.d[2]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template <>
fixed_int<3> imul(i128 const& lhs, i192 const& rhs)
{
    fixed_int<3> res;
    i128 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l02 = u64(l.d[0]) * u64(r.d[2]);
    l11 = u64(l.d[1]) * u64(r.d[1]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l02, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l11, &res.d[2]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template <>
fixed_int<3> imul(i192 const& lhs, i192 const& rhs)
{
    fixed_int<3> res;
    i192 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l20 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l02 = u64(l.d[0]) * u64(r.d[2]);
    l11 = u64(l.d[1]) * u64(r.d[1]);
    l20 = u64(l.d[2]) * u64(r.d[0]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l02, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l11, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l20, &res.d[2]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template <>
fixed_int<3> imul(i256 const& lhs, i192 const& rhs)
{
    fixed_int<3> res;
    i256 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) - s_l;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l20 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l02 = u64(l.d[0]) * u64(r.d[2]);
    l11 = u64(l.d[1]) * u64(r.d[1]);
    l20 = u64(l.d[2]) * u64(r.d[0]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l02, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l11, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l20, &res.d[2]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template <>
fixed_int<3> imul(i64 const& lhs, i256 const& rhs)
{
    fixed_int<3> res;
    i64 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l) >> 63);      // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) - s_r;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    l00 = _mulx_u64(u64(l), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l), u64(r.d[1]), &h01);
    l02 = u64(l) * u64(r.d[2]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l02, &res.d[2]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template <>
fixed_int<3> imul(i128 const& lhs, i256 const& rhs)
{
    fixed_int<3> res;
    i128 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) - s_r;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l02 = u64(l.d[0]) * u64(r.d[2]);
    l11 = u64(l.d[1]) * u64(r.d[1]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l02, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l11, &res.d[2]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template <>
fixed_int<3> imul(i192 const& lhs, i256 const& rhs)
{
    fixed_int<3> res;
    i192 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) - s_r;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l20 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l02 = u64(l.d[0]) * u64(r.d[2]);
    l11 = u64(l.d[1]) * u64(r.d[1]);
    l20 = u64(l.d[2]) * u64(r.d[0]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l02, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l11, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l20, &res.d[2]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template <>
fixed_int<3> imul(i256 const& lhs, i256 const& rhs)
{
    fixed_int<3> res;
    i256 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) - s_l;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) - s_r;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l20 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l02 = u64(l.d[0]) * u64(r.d[2]);
    l11 = u64(l.d[1]) * u64(r.d[1]);
    l20 = u64(l.d[2]) * u64(r.d[0]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l02, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l11, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l20, &res.d[2]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template <>
fixed_int<4> imul(i64 const& lhs, i64 const& rhs)
{
    fixed_int<4> res;
    i64 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l), u64(r), &h00);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) - s_res;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template <>
fixed_int<4> imul(i128 const& lhs, i64 const& rhs)
{
    fixed_int<4> res;
    i128 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63);      // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r), &h00);
    l10 = _mulx_u64(u64(l.d[1]), u64(r), &h10);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) - s_res;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template <>
fixed_int<4> imul(i192 const& lhs, i64 const& rhs)
{
    fixed_int<4> res;
    i192 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63);      // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 l10 = 0;
    u64 l20 = 0;
    u64 h00 = 0;
    u64 h10 = 0;
    u64 h20 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r), &h00);
    l10 = _mulx_u64(u64(l.d[1]), u64(r), &h10);
    l20 = _mulx_u64(u64(l.d[2]), u64(r), &h20);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l20, &res.d[2]);
    c = _addcarry_u64(c, res.d[3], h20, &res.d[3]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) - s_res;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template <>
fixed_int<4> imul(i256 const& lhs, i64 const& rhs)
{
    fixed_int<4> res;
    i256 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63);      // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) - s_l;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 l10 = 0;
    u64 l20 = 0;
    u64 l30 = 0;
    u64 h00 = 0;
    u64 h10 = 0;
    u64 h20 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r), &h00);
    l10 = _mulx_u64(u64(l.d[1]), u64(r), &h10);
    l20 = _mulx_u64(u64(l.d[2]), u64(r), &h20);
    l30 = u64(l.d[3]) * u64(r);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l20, &res.d[2]);
    c = _addcarry_u64(c, res.d[3], h20, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], l30, &res.d[3]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) - s_res;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template <>
fixed_int<4> imul(i64 const& lhs, i128 const& rhs)
{
    fixed_int<4> res;
    i64 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l) >> 63);      // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    l00 = _mulx_u64(u64(l), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l), u64(r.d[1]), &h01);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) - s_res;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template <>
fixed_int<4> imul(i128 const& lhs, i128 const& rhs)
{
    fixed_int<4> res;
    i128 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    u64 h11 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = _mulx_u64(u64(l.d[1]), u64(r.d[1]), &h11);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l11, &res.d[2]);
    c = _addcarry_u64(c, res.d[3], h11, &res.d[3]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) - s_res;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template <>
fixed_int<4> imul(i192 const& lhs, i128 const& rhs)
{
    fixed_int<4> res;
    i192 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l20 = 0;
    u64 l21 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    u64 h11 = 0;
    u64 h20 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = _mulx_u64(u64(l.d[1]), u64(r.d[1]), &h11);
    l20 = _mulx_u64(u64(l.d[2]), u64(r.d[0]), &h20);
    l21 = u64(l.d[2]) * u64(r.d[1]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l11, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l20, &res.d[2]);
    c = _addcarry_u64(c, res.d[3], h11, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], h20, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], l21, &res.d[3]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) - s_res;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template <>
fixed_int<4> imul(i256 const& lhs, i128 const& rhs)
{
    fixed_int<4> res;
    i256 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) - s_l;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l20 = 0;
    u64 l21 = 0;
    u64 l30 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    u64 h11 = 0;
    u64 h20 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = _mulx_u64(u64(l.d[1]), u64(r.d[1]), &h11);
    l20 = _mulx_u64(u64(l.d[2]), u64(r.d[0]), &h20);
    l21 = u64(l.d[2]) * u64(r.d[1]);
    l30 = u64(l.d[3]) * u64(r.d[0]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l11, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l20, &res.d[2]);
    c = _addcarry_u64(c, res.d[3], h11, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], h20, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], l21, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], l30, &res.d[3]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) - s_res;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template <>
fixed_int<4> imul(i64 const& lhs, i192 const& rhs)
{
    fixed_int<4> res;
    i64 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l) >> 63);      // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h02 = 0;
    l00 = _mulx_u64(u64(l), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l), u64(r.d[1]), &h01);
    l02 = _mulx_u64(u64(l), u64(r.d[2]), &h02);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l02, &res.d[2]);
    c = _addcarry_u64(c, res.d[3], h02, &res.d[3]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) - s_res;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template <>
fixed_int<4> imul(i128 const& lhs, i192 const& rhs)
{
    fixed_int<4> res;
    i128 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l12 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h02 = 0;
    u64 h10 = 0;
    u64 h11 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l02 = _mulx_u64(u64(l.d[0]), u64(r.d[2]), &h02);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = _mulx_u64(u64(l.d[1]), u64(r.d[1]), &h11);
    l12 = u64(l.d[1]) * u64(r.d[2]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l02, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l11, &res.d[2]);
    c = _addcarry_u64(c, res.d[3], h02, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], h11, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], l12, &res.d[3]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) - s_res;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template <>
fixed_int<4> imul(i192 const& lhs, i192 const& rhs)
{
    fixed_int<4> res;
    i192 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l12 = 0;
    u64 l20 = 0;
    u64 l21 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h02 = 0;
    u64 h10 = 0;
    u64 h11 = 0;
    u64 h20 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l02 = _mulx_u64(u64(l.d[0]), u64(r.d[2]), &h02);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = _mulx_u64(u64(l.d[1]), u64(r.d[1]), &h11);
    l20 = _mulx_u64(u64(l.d[2]), u64(r.d[0]), &h20);
    l12 = u64(l.d[1]) * u64(r.d[2]);
    l21 = u64(l.d[2]) * u64(r.d[1]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l02, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l11, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l20, &res.d[2]);
    c = _addcarry_u64(c, res.d[3], h02, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], h11, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], l12, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], h20, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], l21, &res.d[3]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) - s_res;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template <>
fixed_int<4> imul(i256 const& lhs, i192 const& rhs)
{
    fixed_int<4> res;
    i256 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) - s_l;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l12 = 0;
    u64 l20 = 0;
    u64 l21 = 0;
    u64 l30 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h02 = 0;
    u64 h10 = 0;
    u64 h11 = 0;
    u64 h20 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l02 = _mulx_u64(u64(l.d[0]), u64(r.d[2]), &h02);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = _mulx_u64(u64(l.d[1]), u64(r.d[1]), &h11);
    l20 = _mulx_u64(u64(l.d[2]), u64(r.d[0]), &h20);
    l12 = u64(l.d[1]) * u64(r.d[2]);
    l21 = u64(l.d[2]) * u64(r.d[1]);
    l30 = u64(l.d[3]) * u64(r.d[0]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l02, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l11, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l20, &res.d[2]);
    c = _addcarry_u64(c, res.d[3], h02, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], h11, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], l12, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], h20, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], l21, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], l30, &res.d[3]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) - s_res;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template <>
fixed_int<4> imul(i64 const& lhs, i256 const& rhs)
{
    fixed_int<4> res;
    i64 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l) >> 63);      // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) - s_r;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l03 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h02 = 0;
    l00 = _mulx_u64(u64(l), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l), u64(r.d[1]), &h01);
    l02 = _mulx_u64(u64(l), u64(r.d[2]), &h02);
    l03 = u64(l) * u64(r.d[3]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l02, &res.d[2]);
    c = _addcarry_u64(c, res.d[3], h02, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], l03, &res.d[3]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) - s_res;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template <>
fixed_int<4> imul(i128 const& lhs, i256 const& rhs)
{
    fixed_int<4> res;
    i128 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) - s_r;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l03 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l12 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h02 = 0;
    u64 h10 = 0;
    u64 h11 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l02 = _mulx_u64(u64(l.d[0]), u64(r.d[2]), &h02);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = _mulx_u64(u64(l.d[1]), u64(r.d[1]), &h11);
    l03 = u64(l.d[0]) * u64(r.d[3]);
    l12 = u64(l.d[1]) * u64(r.d[2]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l02, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l11, &res.d[2]);
    c = _addcarry_u64(c, res.d[3], h02, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], l03, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], h11, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], l12, &res.d[3]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) - s_res;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template <>
fixed_int<4> imul(i192 const& lhs, i256 const& rhs)
{
    fixed_int<4> res;
    i192 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) - s_r;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l03 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l12 = 0;
    u64 l20 = 0;
    u64 l21 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h02 = 0;
    u64 h10 = 0;
    u64 h11 = 0;
    u64 h20 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l02 = _mulx_u64(u64(l.d[0]), u64(r.d[2]), &h02);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = _mulx_u64(u64(l.d[1]), u64(r.d[1]), &h11);
    l20 = _mulx_u64(u64(l.d[2]), u64(r.d[0]), &h20);
    l03 = u64(l.d[0]) * u64(r.d[3]);
    l12 = u64(l.d[1]) * u64(r.d[2]);
    l21 = u64(l.d[2]) * u64(r.d[1]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l02, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l11, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l20, &res.d[2]);
    c = _addcarry_u64(c, res.d[3], h02, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], l03, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], h11, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], l12, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], h20, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], l21, &res.d[3]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) - s_res;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template <>
fixed_int<4> imul(i256 const& lhs, i256 const& rhs)
{
    fixed_int<4> res;
    i256 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) - s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) - s_l;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) - s_l;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) - s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) - s_r;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) - s_r;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l03 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l12 = 0;
    u64 l20 = 0;
    u64 l21 = 0;
    u64 l30 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h02 = 0;
    u64 h10 = 0;
    u64 h11 = 0;
    u64 h20 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l02 = _mulx_u64(u64(l.d[0]), u64(r.d[2]), &h02);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = _mulx_u64(u64(l.d[1]), u64(r.d[1]), &h11);
    l20 = _mulx_u64(u64(l.d[2]), u64(r.d[0]), &h20);
    l03 = u64(l.d[0]) * u64(r.d[3]);
    l12 = u64(l.d[1]) * u64(r.d[2]);
    l21 = u64(l.d[2]) * u64(r.d[1]);
    l30 = u64(l.d[3]) * u64(r.d[0]);
    unsigned char c = 0;
    c = _addcarry_u64(c, res.d[0], l00, &res.d[0]);
    c = _addcarry_u64(c, res.d[1], h00, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l01, &res.d[1]);
    c = _addcarry_u64(c, res.d[1], l10, &res.d[1]);
    c = _addcarry_u64(c, res.d[2], h01, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l02, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], h10, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l11, &res.d[2]);
    c = _addcarry_u64(c, res.d[2], l20, &res.d[2]);
    c = _addcarry_u64(c, res.d[3], h02, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], l03, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], h11, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], l12, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], h20, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], l21, &res.d[3]);
    c = _addcarry_u64(c, res.d[3], l30, &res.d[3]);
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) - s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) - s_res;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) - s_res;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

} // namespace tg::detail
