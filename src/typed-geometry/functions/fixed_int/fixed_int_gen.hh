#pragma once

// This file was generated by generate_fixed_uint_multiplications.cc in TGSamples.

#ifdef _MSV_VER
#include <intrin.h>
#else
#include <x86intrin.h>
#endif

#include <typed-geometry/functions/fixed_int/fixed_int.hh>

namespace tg::detail
{
template <int w_res, class T0, class T1>
fixed_int<w_res> imul(T0 const& lhs, T1 const& rhs);

template<>
inline fixed_int<2> imul(i64 const& lhs, i64 const& rhs)
{
    fixed_int<2> res;
    i64 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l), u64(r), &h00);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    res.d[1] = c + h00;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template<>
inline fixed_int<2> imul(i128 const& lhs, i64 const& rhs)
{
    fixed_int<2> res;
    i128 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r), &h00);
    l10 = u64(l.d[1]) * u64(r);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    res.d[1] = c + h00 + l10;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template<>
inline fixed_int<2> imul(i192 const& lhs, i64 const& rhs)
{
    fixed_int<2> res;
    i192 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r), &h00);
    l10 = u64(l.d[1]) * u64(r);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    res.d[1] = c + h00 + l10;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template<>
inline fixed_int<2> imul(i256 const& lhs, i64 const& rhs)
{
    fixed_int<2> res;
    i256 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) & s_l & c1;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r), &h00);
    l10 = u64(l.d[1]) * u64(r);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    res.d[1] = c + h00 + l10;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template<>
inline fixed_int<2> imul(i64 const& lhs, i128 const& rhs)
{
    fixed_int<2> res;
    i64 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l), u64(r.d[0]), &h00);
    l01 = u64(l) * u64(r.d[1]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    res.d[1] = c + h00 + l01;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template<>
inline fixed_int<2> imul(i128 const& lhs, i128 const& rhs)
{
    fixed_int<2> res;
    i128 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = u64(l.d[0]) * u64(r.d[1]);
    l10 = u64(l.d[1]) * u64(r.d[0]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    res.d[1] = c + h00 + l01 + l10;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template<>
inline fixed_int<2> imul(i192 const& lhs, i128 const& rhs)
{
    fixed_int<2> res;
    i192 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = u64(l.d[0]) * u64(r.d[1]);
    l10 = u64(l.d[1]) * u64(r.d[0]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    res.d[1] = c + h00 + l01 + l10;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template<>
inline fixed_int<2> imul(i256 const& lhs, i128 const& rhs)
{
    fixed_int<2> res;
    i256 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) & s_l & c1;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = u64(l.d[0]) * u64(r.d[1]);
    l10 = u64(l.d[1]) * u64(r.d[0]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    res.d[1] = c + h00 + l01 + l10;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template<>
inline fixed_int<2> imul(i64 const& lhs, i192 const& rhs)
{
    fixed_int<2> res;
    i64 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l), u64(r.d[0]), &h00);
    l01 = u64(l) * u64(r.d[1]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    res.d[1] = c + h00 + l01;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template<>
inline fixed_int<2> imul(i128 const& lhs, i192 const& rhs)
{
    fixed_int<2> res;
    i128 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = u64(l.d[0]) * u64(r.d[1]);
    l10 = u64(l.d[1]) * u64(r.d[0]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    res.d[1] = c + h00 + l01 + l10;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template<>
inline fixed_int<2> imul(i192 const& lhs, i192 const& rhs)
{
    fixed_int<2> res;
    i192 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = u64(l.d[0]) * u64(r.d[1]);
    l10 = u64(l.d[1]) * u64(r.d[0]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    res.d[1] = c + h00 + l01 + l10;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template<>
inline fixed_int<2> imul(i256 const& lhs, i192 const& rhs)
{
    fixed_int<2> res;
    i256 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) & s_l & c1;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = u64(l.d[0]) * u64(r.d[1]);
    l10 = u64(l.d[1]) * u64(r.d[0]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    res.d[1] = c + h00 + l01 + l10;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template<>
inline fixed_int<2> imul(i64 const& lhs, i256 const& rhs)
{
    fixed_int<2> res;
    i64 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) & s_r & c1;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l), u64(r.d[0]), &h00);
    l01 = u64(l) * u64(r.d[1]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    res.d[1] = c + h00 + l01;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template<>
inline fixed_int<2> imul(i128 const& lhs, i256 const& rhs)
{
    fixed_int<2> res;
    i128 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) & s_r & c1;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = u64(l.d[0]) * u64(r.d[1]);
    l10 = u64(l.d[1]) * u64(r.d[0]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    res.d[1] = c + h00 + l01 + l10;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template<>
inline fixed_int<2> imul(i192 const& lhs, i256 const& rhs)
{
    fixed_int<2> res;
    i192 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) & s_r & c1;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = u64(l.d[0]) * u64(r.d[1]);
    l10 = u64(l.d[1]) * u64(r.d[0]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    res.d[1] = c + h00 + l01 + l10;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template<>
inline fixed_int<2> imul(i256 const& lhs, i256 const& rhs)
{
    fixed_int<2> res;
    i256 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) & s_l & c1;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) & s_r & c1;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = u64(l.d[0]) * u64(r.d[1]);
    l10 = u64(l.d[1]) * u64(r.d[0]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    res.d[1] = c + h00 + l01 + l10;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
    }
    return res;
}

template<>
inline fixed_int<3> imul(i64 const& lhs, i64 const& rhs)
{
    fixed_int<3> res;
    i64 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l), u64(r), &h00);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    res.d[2] = c;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template<>
inline fixed_int<3> imul(i128 const& lhs, i64 const& rhs)
{
    fixed_int<3> res;
    i128 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r), &h00);
    l10 = _mulx_u64(u64(l.d[1]), u64(r), &h10);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    res.d[2] = c + h10;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template<>
inline fixed_int<3> imul(i192 const& lhs, i64 const& rhs)
{
    fixed_int<3> res;
    i192 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 l10 = 0;
    u64 l20 = 0;
    u64 h00 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r), &h00);
    l10 = _mulx_u64(u64(l.d[1]), u64(r), &h10);
    l20 = u64(l.d[2]) * u64(r);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    res.d[2] = c + h10 + l20;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template<>
inline fixed_int<3> imul(i256 const& lhs, i64 const& rhs)
{
    fixed_int<3> res;
    i256 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) & s_l & c1;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 l10 = 0;
    u64 l20 = 0;
    u64 h00 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r), &h00);
    l10 = _mulx_u64(u64(l.d[1]), u64(r), &h10);
    l20 = u64(l.d[2]) * u64(r);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    res.d[2] = c + h10 + l20;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template<>
inline fixed_int<3> imul(i64 const& lhs, i128 const& rhs)
{
    fixed_int<3> res;
    i64 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    l00 = _mulx_u64(u64(l), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l), u64(r.d[1]), &h01);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    res.d[2] = c + h01;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template<>
inline fixed_int<3> imul(i128 const& lhs, i128 const& rhs)
{
    fixed_int<3> res;
    i128 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = u64(l.d[1]) * u64(r.d[1]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    res.d[2] = c + h01 + h10 + l11;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template<>
inline fixed_int<3> imul(i192 const& lhs, i128 const& rhs)
{
    fixed_int<3> res;
    i192 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l20 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = u64(l.d[1]) * u64(r.d[1]);
    l20 = u64(l.d[2]) * u64(r.d[0]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    res.d[2] = c + h01 + h10 + l11 + l20;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template<>
inline fixed_int<3> imul(i256 const& lhs, i128 const& rhs)
{
    fixed_int<3> res;
    i256 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) & s_l & c1;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l20 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = u64(l.d[1]) * u64(r.d[1]);
    l20 = u64(l.d[2]) * u64(r.d[0]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    res.d[2] = c + h01 + h10 + l11 + l20;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template<>
inline fixed_int<3> imul(i64 const& lhs, i192 const& rhs)
{
    fixed_int<3> res;
    i64 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    l00 = _mulx_u64(u64(l), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l), u64(r.d[1]), &h01);
    l02 = u64(l) * u64(r.d[2]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    res.d[2] = c + h01 + l02;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template<>
inline fixed_int<3> imul(i128 const& lhs, i192 const& rhs)
{
    fixed_int<3> res;
    i128 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l02 = u64(l.d[0]) * u64(r.d[2]);
    l11 = u64(l.d[1]) * u64(r.d[1]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    res.d[2] = c + h01 + l02 + h10 + l11;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template<>
inline fixed_int<3> imul(i192 const& lhs, i192 const& rhs)
{
    fixed_int<3> res;
    i192 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l20 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l02 = u64(l.d[0]) * u64(r.d[2]);
    l11 = u64(l.d[1]) * u64(r.d[1]);
    l20 = u64(l.d[2]) * u64(r.d[0]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    res.d[2] = c + h01 + l02 + h10 + l11 + l20;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template<>
inline fixed_int<3> imul(i256 const& lhs, i192 const& rhs)
{
    fixed_int<3> res;
    i256 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) & s_l & c1;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l20 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l02 = u64(l.d[0]) * u64(r.d[2]);
    l11 = u64(l.d[1]) * u64(r.d[1]);
    l20 = u64(l.d[2]) * u64(r.d[0]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    res.d[2] = c + h01 + l02 + h10 + l11 + l20;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template<>
inline fixed_int<3> imul(i64 const& lhs, i256 const& rhs)
{
    fixed_int<3> res;
    i64 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) & s_r & c1;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    l00 = _mulx_u64(u64(l), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l), u64(r.d[1]), &h01);
    l02 = u64(l) * u64(r.d[2]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    res.d[2] = c + h01 + l02;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template<>
inline fixed_int<3> imul(i128 const& lhs, i256 const& rhs)
{
    fixed_int<3> res;
    i128 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) & s_r & c1;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l02 = u64(l.d[0]) * u64(r.d[2]);
    l11 = u64(l.d[1]) * u64(r.d[1]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    res.d[2] = c + h01 + l02 + h10 + l11;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template<>
inline fixed_int<3> imul(i192 const& lhs, i256 const& rhs)
{
    fixed_int<3> res;
    i192 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) & s_r & c1;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l20 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l02 = u64(l.d[0]) * u64(r.d[2]);
    l11 = u64(l.d[1]) * u64(r.d[1]);
    l20 = u64(l.d[2]) * u64(r.d[0]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    res.d[2] = c + h01 + l02 + h10 + l11 + l20;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template<>
inline fixed_int<3> imul(i256 const& lhs, i256 const& rhs)
{
    fixed_int<3> res;
    i256 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) & s_l & c1;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) & s_r & c1;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l20 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l02 = u64(l.d[0]) * u64(r.d[2]);
    l11 = u64(l.d[1]) * u64(r.d[1]);
    l20 = u64(l.d[2]) * u64(r.d[0]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    res.d[2] = c + h01 + l02 + h10 + l11 + l20;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
    }
    return res;
}

template<>
inline fixed_int<4> imul(i64 const& lhs, i64 const& rhs)
{
    fixed_int<4> res;
    i64 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 h00 = 0;
    l00 = _mulx_u64(u64(l), u64(r), &h00);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[2], c, &res.d[2]);
    c = 0;
    res.d[3] = c;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) & s_res & c1;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template<>
inline fixed_int<4> imul(i128 const& lhs, i64 const& rhs)
{
    fixed_int<4> res;
    i128 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 l10 = 0;
    u64 h00 = 0;
    u64 h10 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r), &h00);
    l10 = _mulx_u64(u64(l.d[1]), u64(r), &h10);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    c += _addcarry_u64(0, res.d[2], c, &res.d[2]);
    c = 0;
    c += _addcarry_u64(0, res.d[2], h10, &res.d[2]);
    res.d[3] = c;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) & s_res & c1;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template<>
inline fixed_int<4> imul(i192 const& lhs, i64 const& rhs)
{
    fixed_int<4> res;
    i192 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 l10 = 0;
    u64 l20 = 0;
    u64 h00 = 0;
    u64 h10 = 0;
    u64 h20 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r), &h00);
    l10 = _mulx_u64(u64(l.d[1]), u64(r), &h10);
    l20 = _mulx_u64(u64(l.d[2]), u64(r), &h20);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    c += _addcarry_u64(0, res.d[2], c, &res.d[2]);
    c = 0;
    c += _addcarry_u64(0, res.d[2], h10, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l20, &res.d[2]);
    res.d[3] = c + h20;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) & s_res & c1;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template<>
inline fixed_int<4> imul(i256 const& lhs, i64 const& rhs)
{
    fixed_int<4> res;
    i256 l = lhs;
    i64 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) & s_l & c1;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r = i64((u64(r) ^ s_r) - s_r);
    }
    u64 l00 = 0;
    u64 l10 = 0;
    u64 l20 = 0;
    u64 l30 = 0;
    u64 h00 = 0;
    u64 h10 = 0;
    u64 h20 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r), &h00);
    l10 = _mulx_u64(u64(l.d[1]), u64(r), &h10);
    l20 = _mulx_u64(u64(l.d[2]), u64(r), &h20);
    l30 = u64(l.d[3]) * u64(r);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    c += _addcarry_u64(0, res.d[2], c, &res.d[2]);
    c = 0;
    c += _addcarry_u64(0, res.d[2], h10, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l20, &res.d[2]);
    res.d[3] = c + h20 + l30;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) & s_res & c1;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template<>
inline fixed_int<4> imul(i64 const& lhs, i128 const& rhs)
{
    fixed_int<4> res;
    i64 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    l00 = _mulx_u64(u64(l), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l), u64(r.d[1]), &h01);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    c += _addcarry_u64(0, res.d[2], c, &res.d[2]);
    c = 0;
    c += _addcarry_u64(0, res.d[2], h01, &res.d[2]);
    res.d[3] = c;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) & s_res & c1;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template<>
inline fixed_int<4> imul(i128 const& lhs, i128 const& rhs)
{
    fixed_int<4> res;
    i128 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    u64 h11 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = _mulx_u64(u64(l.d[1]), u64(r.d[1]), &h11);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    c += _addcarry_u64(0, res.d[2], c, &res.d[2]);
    c = 0;
    c += _addcarry_u64(0, res.d[2], h01, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], h10, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l11, &res.d[2]);
    res.d[3] = c + h11;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) & s_res & c1;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template<>
inline fixed_int<4> imul(i192 const& lhs, i128 const& rhs)
{
    fixed_int<4> res;
    i192 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l20 = 0;
    u64 l21 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    u64 h11 = 0;
    u64 h20 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = _mulx_u64(u64(l.d[1]), u64(r.d[1]), &h11);
    l20 = _mulx_u64(u64(l.d[2]), u64(r.d[0]), &h20);
    l21 = u64(l.d[2]) * u64(r.d[1]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    c += _addcarry_u64(0, res.d[2], c, &res.d[2]);
    c = 0;
    c += _addcarry_u64(0, res.d[2], h01, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], h10, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l11, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l20, &res.d[2]);
    res.d[3] = c + h11 + h20 + l21;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) & s_res & c1;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template<>
inline fixed_int<4> imul(i256 const& lhs, i128 const& rhs)
{
    fixed_int<4> res;
    i256 l = lhs;
    i128 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) & s_l & c1;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l20 = 0;
    u64 l21 = 0;
    u64 l30 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h10 = 0;
    u64 h11 = 0;
    u64 h20 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = _mulx_u64(u64(l.d[1]), u64(r.d[1]), &h11);
    l20 = _mulx_u64(u64(l.d[2]), u64(r.d[0]), &h20);
    l21 = u64(l.d[2]) * u64(r.d[1]);
    l30 = u64(l.d[3]) * u64(r.d[0]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    c += _addcarry_u64(0, res.d[2], c, &res.d[2]);
    c = 0;
    c += _addcarry_u64(0, res.d[2], h01, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], h10, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l11, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l20, &res.d[2]);
    res.d[3] = c + h11 + h20 + l21 + l30;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) & s_res & c1;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template<>
inline fixed_int<4> imul(i64 const& lhs, i192 const& rhs)
{
    fixed_int<4> res;
    i64 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h02 = 0;
    l00 = _mulx_u64(u64(l), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l), u64(r.d[1]), &h01);
    l02 = _mulx_u64(u64(l), u64(r.d[2]), &h02);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    c += _addcarry_u64(0, res.d[2], c, &res.d[2]);
    c = 0;
    c += _addcarry_u64(0, res.d[2], h01, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l02, &res.d[2]);
    res.d[3] = c + h02;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) & s_res & c1;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template<>
inline fixed_int<4> imul(i128 const& lhs, i192 const& rhs)
{
    fixed_int<4> res;
    i128 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l12 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h02 = 0;
    u64 h10 = 0;
    u64 h11 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l02 = _mulx_u64(u64(l.d[0]), u64(r.d[2]), &h02);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = _mulx_u64(u64(l.d[1]), u64(r.d[1]), &h11);
    l12 = u64(l.d[1]) * u64(r.d[2]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    c += _addcarry_u64(0, res.d[2], c, &res.d[2]);
    c = 0;
    c += _addcarry_u64(0, res.d[2], h01, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l02, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], h10, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l11, &res.d[2]);
    res.d[3] = c + h02 + h11 + l12;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) & s_res & c1;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template<>
inline fixed_int<4> imul(i192 const& lhs, i192 const& rhs)
{
    fixed_int<4> res;
    i192 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l12 = 0;
    u64 l20 = 0;
    u64 l21 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h02 = 0;
    u64 h10 = 0;
    u64 h11 = 0;
    u64 h20 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l02 = _mulx_u64(u64(l.d[0]), u64(r.d[2]), &h02);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = _mulx_u64(u64(l.d[1]), u64(r.d[1]), &h11);
    l20 = _mulx_u64(u64(l.d[2]), u64(r.d[0]), &h20);
    l12 = u64(l.d[1]) * u64(r.d[2]);
    l21 = u64(l.d[2]) * u64(r.d[1]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    c += _addcarry_u64(0, res.d[2], c, &res.d[2]);
    c = 0;
    c += _addcarry_u64(0, res.d[2], h01, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l02, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], h10, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l11, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l20, &res.d[2]);
    res.d[3] = c + h02 + h11 + l12 + h20 + l21;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) & s_res & c1;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template<>
inline fixed_int<4> imul(i256 const& lhs, i192 const& rhs)
{
    fixed_int<4> res;
    i256 l = lhs;
    i192 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) & s_l & c1;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l12 = 0;
    u64 l20 = 0;
    u64 l21 = 0;
    u64 l30 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h02 = 0;
    u64 h10 = 0;
    u64 h11 = 0;
    u64 h20 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l02 = _mulx_u64(u64(l.d[0]), u64(r.d[2]), &h02);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = _mulx_u64(u64(l.d[1]), u64(r.d[1]), &h11);
    l20 = _mulx_u64(u64(l.d[2]), u64(r.d[0]), &h20);
    l12 = u64(l.d[1]) * u64(r.d[2]);
    l21 = u64(l.d[2]) * u64(r.d[1]);
    l30 = u64(l.d[3]) * u64(r.d[0]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    c += _addcarry_u64(0, res.d[2], c, &res.d[2]);
    c = 0;
    c += _addcarry_u64(0, res.d[2], h01, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l02, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], h10, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l11, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l20, &res.d[2]);
    res.d[3] = c + h02 + h11 + l12 + h20 + l21 + l30;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) & s_res & c1;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template<>
inline fixed_int<4> imul(i64 const& lhs, i256 const& rhs)
{
    fixed_int<4> res;
    i64 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l = i64((u64(l) ^ s_l) - s_l);
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) & s_r & c1;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l03 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h02 = 0;
    l00 = _mulx_u64(u64(l), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l), u64(r.d[1]), &h01);
    l02 = _mulx_u64(u64(l), u64(r.d[2]), &h02);
    l03 = u64(l) * u64(r.d[3]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    c += _addcarry_u64(0, res.d[2], c, &res.d[2]);
    c = 0;
    c += _addcarry_u64(0, res.d[2], h01, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l02, &res.d[2]);
    res.d[3] = c + h02 + l03;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) & s_res & c1;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template<>
inline fixed_int<4> imul(i128 const& lhs, i256 const& rhs)
{
    fixed_int<4> res;
    i128 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l.d[1]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) & s_r & c1;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l03 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l12 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h02 = 0;
    u64 h10 = 0;
    u64 h11 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l02 = _mulx_u64(u64(l.d[0]), u64(r.d[2]), &h02);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = _mulx_u64(u64(l.d[1]), u64(r.d[1]), &h11);
    l03 = u64(l.d[0]) * u64(r.d[3]);
    l12 = u64(l.d[1]) * u64(r.d[2]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    c += _addcarry_u64(0, res.d[2], c, &res.d[2]);
    c = 0;
    c += _addcarry_u64(0, res.d[2], h01, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l02, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], h10, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l11, &res.d[2]);
    res.d[3] = c + h02 + l03 + h11 + l12;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) & s_res & c1;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template<>
inline fixed_int<4> imul(i192 const& lhs, i256 const& rhs)
{
    fixed_int<4> res;
    i192 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l.d[2]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) & s_r & c1;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l03 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l12 = 0;
    u64 l20 = 0;
    u64 l21 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h02 = 0;
    u64 h10 = 0;
    u64 h11 = 0;
    u64 h20 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l02 = _mulx_u64(u64(l.d[0]), u64(r.d[2]), &h02);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = _mulx_u64(u64(l.d[1]), u64(r.d[1]), &h11);
    l20 = _mulx_u64(u64(l.d[2]), u64(r.d[0]), &h20);
    l03 = u64(l.d[0]) * u64(r.d[3]);
    l12 = u64(l.d[1]) * u64(r.d[2]);
    l21 = u64(l.d[2]) * u64(r.d[1]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    c += _addcarry_u64(0, res.d[2], c, &res.d[2]);
    c = 0;
    c += _addcarry_u64(0, res.d[2], h01, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l02, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], h10, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l11, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l20, &res.d[2]);
    res.d[3] = c + h02 + l03 + h11 + l12 + h20 + l21;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) & s_res & c1;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

template<>
inline fixed_int<4> imul(i256 const& lhs, i256 const& rhs)
{
    fixed_int<4> res;
    i256 l = lhs;
    i256 r = rhs;
    u64 s_l = u64(i64(l.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_r = u64(i64(r.d[3]) >> 63); // 0 iff > 0, -1 otherwise
    u64 s_res = s_l ^ s_r;
    { // conditional inversion
        l.d[0] = ((u64(l.d[0]) ^ s_l) - s_l);
        u64 c0 = (l.d[0] == 0) & s_l;
        l.d[1] = (u64(l.d[1]) ^ s_l) + c0;
        u64 c1 = (l.d[1] == 0) & s_l & c0;
        l.d[2] = (u64(l.d[2]) ^ s_l) + c1;
        u64 c2 = (l.d[2] == 0) & s_l & c1;
        l.d[3] = (u64(l.d[3]) ^ s_l) + c2;
    }
    { // conditional inversion
        r.d[0] = ((u64(r.d[0]) ^ s_r) - s_r);
        u64 c0 = (r.d[0] == 0) & s_r;
        r.d[1] = (u64(r.d[1]) ^ s_r) + c0;
        u64 c1 = (r.d[1] == 0) & s_r & c0;
        r.d[2] = (u64(r.d[2]) ^ s_r) + c1;
        u64 c2 = (r.d[2] == 0) & s_r & c1;
        r.d[3] = (u64(r.d[3]) ^ s_r) + c2;
    }
    u64 l00 = 0;
    u64 l01 = 0;
    u64 l02 = 0;
    u64 l03 = 0;
    u64 l10 = 0;
    u64 l11 = 0;
    u64 l12 = 0;
    u64 l20 = 0;
    u64 l21 = 0;
    u64 l30 = 0;
    u64 h00 = 0;
    u64 h01 = 0;
    u64 h02 = 0;
    u64 h10 = 0;
    u64 h11 = 0;
    u64 h20 = 0;
    l00 = _mulx_u64(u64(l.d[0]), u64(r.d[0]), &h00);
    l01 = _mulx_u64(u64(l.d[0]), u64(r.d[1]), &h01);
    l02 = _mulx_u64(u64(l.d[0]), u64(r.d[2]), &h02);
    l10 = _mulx_u64(u64(l.d[1]), u64(r.d[0]), &h10);
    l11 = _mulx_u64(u64(l.d[1]), u64(r.d[1]), &h11);
    l20 = _mulx_u64(u64(l.d[2]), u64(r.d[0]), &h20);
    l03 = u64(l.d[0]) * u64(r.d[3]);
    l12 = u64(l.d[1]) * u64(r.d[2]);
    l21 = u64(l.d[2]) * u64(r.d[1]);
    l30 = u64(l.d[3]) * u64(r.d[0]);
    unsigned char c = 0;
    c += _addcarry_u64(0, res.d[0], l00, &res.d[0]);
    c += _addcarry_u64(0, res.d[1], c, &res.d[1]);
    c = 0;
    c += _addcarry_u64(0, res.d[1], h00, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l01, &res.d[1]);
    c += _addcarry_u64(0, res.d[1], l10, &res.d[1]);
    c += _addcarry_u64(0, res.d[2], c, &res.d[2]);
    c = 0;
    c += _addcarry_u64(0, res.d[2], h01, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l02, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], h10, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l11, &res.d[2]);
    c += _addcarry_u64(0, res.d[2], l20, &res.d[2]);
    res.d[3] = c + h02 + l03 + h11 + l12 + h20 + l21 + l30;
    { // conditional inversion
        res.d[0] = ((u64(res.d[0]) ^ s_res) - s_res);
        u64 c0 = (res.d[0] == 0) & s_res;
        res.d[1] = (u64(res.d[1]) ^ s_res) + c0;
        u64 c1 = (res.d[1] == 0) & s_res & c0;
        res.d[2] = (u64(res.d[2]) ^ s_res) + c1;
        u64 c2 = (res.d[2] == 0) & s_res & c1;
        res.d[3] = (u64(res.d[3]) ^ s_res) + c2;
    }
    return res;
}

} // namespace tg::detail
